{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Experiment 1: Baseline (No RAG)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T21:19:13.306241Z",
     "iopub.status.busy": "2025-12-22T21:19:13.306171Z",
     "iopub.status.idle": "2025-12-22T21:19:15.611708Z",
     "shell.execute_reply": "2025-12-22T21:19:15.611285Z"
    }
   },
   "source": "# Setup\nimport sys\nimport json\nfrom pathlib import Path\nfrom typing import Dict, List, Any\nfrom dataclasses import dataclass, asdict\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nsys.path.append('..')\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (12, 6)\n\nprint(\"Imports loaded\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T21:19:15.627189Z",
     "iopub.status.busy": "2025-12-22T21:19:15.626946Z",
     "iopub.status.idle": "2025-12-22T21:19:15.652210Z",
     "shell.execute_reply": "2025-12-22T21:19:15.651861Z"
    }
   },
   "source": [
    "# Configuration\n",
    "MODEL_PATH = Path(\"/home/sskaplun/study/genAI/kaggle/models/gemma-2-9b-it\")\n",
    "OUTPUT_DIR = Path(\"../evaluation/experiment_01\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Generation parameters\n",
    "TEMPERATURE = 0.7\n",
    "MAX_NEW_TOKENS = 512\n",
    "\n",
    "print(f\"Model: {MODEL_PATH}\")\n",
    "print(f\"Output: {OUTPUT_DIR}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T21:19:15.653322Z",
     "iopub.status.busy": "2025-12-22T21:19:15.653236Z",
     "iopub.status.idle": "2025-12-22T21:19:15.655309Z",
     "shell.execute_reply": "2025-12-22T21:19:15.654957Z"
    }
   },
   "source": "@dataclass\nclass BaselineResponse:\n    question: str\n    answer: str\n    temperature: float\n    answer_length: int\n    \n    def to_dict(self):\n        return asdict(self)\n\nprint(\"Dataclass defined\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T21:19:15.656166Z",
     "iopub.status.busy": "2025-12-22T21:19:15.656090Z",
     "iopub.status.idle": "2025-12-22T21:19:26.145039Z",
     "shell.execute_reply": "2025-12-22T21:19:26.144599Z"
    }
   },
   "source": "print(\"=\"*80)\nprint(\"LOADING GEMMA-2-9B-INSTRUCT\")\nprint(\"=\"*80)\n\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\"\n)\n\ntokenizer = AutoTokenizer.from_pretrained(str(MODEL_PATH))\nprint(\"Tokenizer loaded\")\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    str(MODEL_PATH),\n    quantization_config=quantization_config,\n    device_map=\"auto\",\n    torch_dtype=torch.float16\n)\nprint(\"Model loaded\")\n\nif torch.cuda.is_available():\n    memory_used = torch.cuda.memory_allocated() / 1024**3\n    print(f\"\\nGPU Memory: {memory_used:.2f} GB\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define System Prompt & Generation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T21:19:26.146259Z",
     "iopub.status.busy": "2025-12-22T21:19:26.146019Z",
     "iopub.status.idle": "2025-12-22T21:19:26.148193Z",
     "shell.execute_reply": "2025-12-22T21:19:26.147821Z"
    }
   },
   "source": "SYSTEM_PROMPT = \"\"\"Ти — досвідчений викладач математики для українських учнів 10-11 класів.\n\nТвоє завдання:\n- Згенерувати математичну задачу з рішенням\n- Використовувати ТІЛЬКИ українську мову\n- Надати чітке пояснення та крок-за-кроком розв'язання\n- Використовувати коректну українську математичну термінологію\n\nФормат відповіді:\n**Задача:** [текст задачі]\n\n**Розв'язання:**\n[покрокове рішення]\n\n**Відповідь:** [фінальна відповідь]\"\"\"\n\nprint(\"System prompt defined\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T21:19:26.149045Z",
     "iopub.status.busy": "2025-12-22T21:19:26.148964Z",
     "iopub.status.idle": "2025-12-22T21:19:26.151703Z",
     "shell.execute_reply": "2025-12-22T21:19:26.151346Z"
    }
   },
   "source": "def generate_baseline(\n    question: str,\n    temperature: float = TEMPERATURE,\n    max_new_tokens: int = MAX_NEW_TOKENS\n) -> BaselineResponse:\n    \"\"\"Generate answer using LLM only (no RAG context).\"\"\"\n    prompt = f\"{SYSTEM_PROMPT}\\n\\nЗАПИТАННЯ:\\n{question}\\n\\nТВОЯ ВІДПОВІДЬ:\"\n    \n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    formatted_prompt = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n    \n    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(model.device)\n    \n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            temperature=temperature,\n            top_p=0.9,\n            do_sample=temperature > 0,\n            pad_token_id=tokenizer.eos_token_id\n        )\n    \n    answer = tokenizer.decode(\n        outputs[0][inputs['input_ids'].shape[1]:],\n        skip_special_tokens=True\n    ).strip()\n    \n    return BaselineResponse(\n        question=question,\n        answer=answer,\n        temperature=temperature,\n        answer_length=len(answer)\n    )\n\nprint(\"Generation function defined\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Questions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T21:19:26.152521Z",
     "iopub.status.busy": "2025-12-22T21:19:26.152440Z",
     "iopub.status.idle": "2025-12-22T21:19:26.154302Z",
     "shell.execute_reply": "2025-12-22T21:19:26.153961Z"
    }
   },
   "source": "from common import STANDARD_TEST_QUESTIONS, EVALUATION_DATASET\n\nTEST_QUESTIONS = STANDARD_TEST_QUESTIONS\nprint(f\"Test set: {len(TEST_QUESTIONS)} questions\")\n\n# Create mapping of questions to expected answers\nquestion_to_expected = {q['input']: q['expected_answer'] for q in EVALUATION_DATASET}\nprint(f\"Expected answers loaded for {len(question_to_expected)} questions\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Baseline Experiment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T21:19:26.155141Z",
     "iopub.status.busy": "2025-12-22T21:19:26.155054Z",
     "iopub.status.idle": "2025-12-22T21:20:49.441792Z",
     "shell.execute_reply": "2025-12-22T21:20:49.441246Z"
    }
   },
   "source": "print(\"=\"*80)\nprint(\"RUNNING BASELINE EXPERIMENT (NO RAG)\")\nprint(\"=\"*80)\n\nresponses = []\n\nfor i, question in enumerate(TEST_QUESTIONS, 1):\n    print(f\"\\n[{i}/{len(TEST_QUESTIONS)}] {question}\")\n    print(\"-\"*80)\n    \n    response = generate_baseline(question)\n    responses.append(response)\n    \n    print(f\"\\n{response.answer}\")\n    print(f\"\\nLength: {response.answer_length} chars\")\n\nprint(f\"\\n{'='*80}\")\nprint(f\"Generated {len(responses)} responses\")\nprint(\"=\"*80)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import common\n\nprint(\"Evaluation functions loaded from common.py\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T21:20:49.447076Z",
     "iopub.status.busy": "2025-12-22T21:20:49.447001Z",
     "iopub.status.idle": "2025-12-22T21:20:49.450426Z",
     "shell.execute_reply": "2025-12-22T21:20:49.450091Z"
    }
   },
   "source": "# Evaluate all responses\nprint(\"=\"*80)\nprint(\"EVALUATION\")\nprint(\"=\"*80)\n\nevaluations = []\n\nfor i, response in enumerate(responses, 1):\n    # Get expected answer for this question\n    expected = question_to_expected.get(response.question, None)\n    \n    # Evaluate with expected answer for correctness\n    metrics = common.evaluate_baseline(\n        response.answer, \n        response.answer_length,\n        expected_answer=expected\n    )\n    \n    evaluations.append({\n        'question': response.question,\n        'metrics': metrics,\n        'answer_length': response.answer_length,\n        'expected_answer': expected\n    })\n    \n    print(f\"\\n{i}. {response.question[:50]}...\")\n    print(f\"   Overall: {metrics['overall_score']:.3f} | \"\n          f\"Ukrainian: {metrics['ukrainian_ratio']:.3f} | \"\n          f\"Correctness: {metrics['correctness']:.3f} | \"\n          f\"Structure: {metrics['has_structure']}\")\n\n# Summary statistics\nprint(f\"\\n{'='*80}\")\nprint(\"SUMMARY\")\nprint(\"=\"*80)\n\navg_metrics = {\n    'overall_score': np.mean([e['metrics']['overall_score'] for e in evaluations]),\n    'ukrainian_ratio': np.mean([e['metrics']['ukrainian_ratio'] for e in evaluations]),\n    'completeness': np.mean([e['metrics']['completeness'] for e in evaluations]),\n    'structure_rate': sum(e['metrics']['has_structure'] for e in evaluations) / len(evaluations),\n    'correctness': np.mean([e['metrics']['correctness'] for e in evaluations])\n}\n\nfor key, value in avg_metrics.items():\n    print(f\"  {key:20s}: {value:.3f}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T21:20:49.451262Z",
     "iopub.status.busy": "2025-12-22T21:20:49.451192Z",
     "iopub.status.idle": "2025-12-22T21:20:49.454721Z",
     "shell.execute_reply": "2025-12-22T21:20:49.454305Z"
    }
   },
   "source": [
    "# Create dataframe\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        'question_num': i+1,\n",
    "        'question': e['question'][:40] + '...',\n",
    "        'overall': e['metrics']['overall_score'],\n",
    "        'ukrainian': e['metrics']['ukrainian_ratio'],\n",
    "        'structure': int(e['metrics']['has_structure']),\n",
    "        'length': e['answer_length']\n",
    "    }\n",
    "    for i, e in enumerate(evaluations)\n",
    "])\n",
    "\n",
    "print(df.to_string())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T21:20:49.455551Z",
     "iopub.status.busy": "2025-12-22T21:20:49.455460Z",
     "iopub.status.idle": "2025-12-22T21:20:49.669494Z",
     "shell.execute_reply": "2025-12-22T21:20:49.669016Z"
    }
   },
   "source": "common.create_metrics_visualization(\n    evaluations=evaluations,\n    avg_metrics=avg_metrics,\n    output_path=OUTPUT_DIR / 'baseline_metrics.png',\n    experiment_name='Baseline',\n    metric_names=['ukrainian_ratio', 'completeness', 'correctness', 'structure_rate']\n)\n\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T21:20:49.670556Z",
     "iopub.status.busy": "2025-12-22T21:20:49.670480Z",
     "iopub.status.idle": "2025-12-22T21:20:49.674049Z",
     "shell.execute_reply": "2025-12-22T21:20:49.673702Z"
    }
   },
   "source": "results = {\n    'experiment': 'baseline_no_rag',\n    'description': 'LLM-only generation without retrieval context',\n    'model': 'gemma-2-9b-it',\n    'temperature': TEMPERATURE,\n    'avg_metrics': avg_metrics,\n    'responses': [r.to_dict() for r in responses],\n    'evaluations': evaluations\n}\n\nwith open(OUTPUT_DIR / 'results.json', 'w', encoding='utf-8') as f:\n    json.dump(results, f, ensure_ascii=False, indent=2)\n\ndf.to_csv(OUTPUT_DIR / 'evaluation.csv', index=False)\n\nprint(f\"Results saved to {OUTPUT_DIR}\")\nprint(\"\\n\" + \"=\"*80)\nprint(\"EXPERIMENT 1 COMPLETE\")\nprint(\"=\"*80)\nprint(f\"\\nOverall Score: {avg_metrics['overall_score']:.3f}\")\nprint(f\"Ukrainian Ratio: {avg_metrics['ukrainian_ratio']:.3f}\")\nprint(f\"Correctness: {avg_metrics['correctness']:.3f}\")\nprint(f\"Structure Rate: {avg_metrics['structure_rate']:.3f}\")",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1cb88d3bb5e9436886b6c933aeea2cff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_50a264ce4f6745f79c6e3a2ccbb36540",
        "IPY_MODEL_70ae5d733bd04ffdb53391a60163f64d",
        "IPY_MODEL_a50b55a7b4c14d67a8a30d39e1b34753"
       ],
       "layout": "IPY_MODEL_fa614ba864cd4764864f6c6031824897",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3238533bc54b48e1b28c11a1ffece0cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "50a264ce4f6745f79c6e3a2ccbb36540": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_727ddcd074e04d45939b11e300f454c9",
       "placeholder": "​",
       "style": "IPY_MODEL_87894c0b3a444dfbb6cc47784a470726",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "70ae5d733bd04ffdb53391a60163f64d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c30fbbed32ce4049a5eb9867adcd4ff4",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3238533bc54b48e1b28c11a1ffece0cf",
       "tabbable": null,
       "tooltip": null,
       "value": 4
      }
     },
     "727ddcd074e04d45939b11e300f454c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "87894c0b3a444dfbb6cc47784a470726": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a50b55a7b4c14d67a8a30d39e1b34753": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ee1db42347894a9f927c31481bbc0e15",
       "placeholder": "​",
       "style": "IPY_MODEL_f52aaa4bda434fbb92b4213217e65c36",
       "tabbable": null,
       "tooltip": null,
       "value": " 4/4 [00:08&lt;00:00,  2.14s/it]"
      }
     },
     "c30fbbed32ce4049a5eb9867adcd4ff4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee1db42347894a9f927c31481bbc0e15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f52aaa4bda434fbb92b4213217e65c36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fa614ba864cd4764864f6c6031824897": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
